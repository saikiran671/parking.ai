{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyORpQ2G5tgCcHuJ8HsDPdKR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"31cea186f069457b8fbcaf3c45edfbf5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_81faa191ce0b4bfd84e744bf90719502","IPY_MODEL_bce7460107a94f8eb1d1d1464c9b41b7","IPY_MODEL_fcc6ac6d76bc428d99cf414cbcaa2e08"],"layout":"IPY_MODEL_b379b57db7c24e7daa06646ae5efb489"}},"81faa191ce0b4bfd84e744bf90719502":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ed1e4070acb4ab88573f323c5a7a096","placeholder":"​","style":"IPY_MODEL_440cd9b027a543e2a1b6cbe3e936627d","value":"100%"}},"bce7460107a94f8eb1d1d1464c9b41b7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c4b76cccc024da7b95c7f08cb1b74de","max":120,"min":0,"orientation":"horizontal","style":"IPY_MODEL_029d30d098d14796bea219657c71f3f9","value":120}},"fcc6ac6d76bc428d99cf414cbcaa2e08":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c7ecf798d5654834a97b4d204f5323ee","placeholder":"​","style":"IPY_MODEL_7085a0db00c04ab89eeb3d7c9a1c6ed1","value":" 120/120 [00:09&lt;00:00, 69.57it/s]"}},"b379b57db7c24e7daa06646ae5efb489":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ed1e4070acb4ab88573f323c5a7a096":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"440cd9b027a543e2a1b6cbe3e936627d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4c4b76cccc024da7b95c7f08cb1b74de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"029d30d098d14796bea219657c71f3f9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c7ecf798d5654834a97b4d204f5323ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7085a0db00c04ab89eeb3d7c9a1c6ed1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"971309971cf1445c9e350380048399d9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2094b3c34cb240cb8282e306b78c3939","IPY_MODEL_55841be796e546d29b24af0c2ec1bd3c","IPY_MODEL_aff06009375c42f79ca3b7c2477c3664"],"layout":"IPY_MODEL_1ecd3f0667384085b04138ec2ff6b1c5"}},"2094b3c34cb240cb8282e306b78c3939":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc28e4fe04bd44239740d8e240767809","placeholder":"​","style":"IPY_MODEL_5d12733097de42888d353c53a1c2ca69","value":"100%"}},"55841be796e546d29b24af0c2ec1bd3c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_85ba7706829b4c969c961ed413ec9637","max":30,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3bf749e425844789a103c3e7dc07fa77","value":30}},"aff06009375c42f79ca3b7c2477c3664":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_09fe82f775cb4843af03a49da2e8379c","placeholder":"​","style":"IPY_MODEL_86327ed9f7894ceabc0e426755954ca0","value":" 30/30 [00:00&lt;00:00, 110.04it/s]"}},"1ecd3f0667384085b04138ec2ff6b1c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc28e4fe04bd44239740d8e240767809":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d12733097de42888d353c53a1c2ca69":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"85ba7706829b4c969c961ed413ec9637":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3bf749e425844789a103c3e7dc07fa77":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"09fe82f775cb4843af03a49da2e8379c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86327ed9f7894ceabc0e426755954ca0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"r1c4jIT0-B6k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1731599505653,"user_tz":-330,"elapsed":6720,"user":{"displayName":"Sai Kiran","userId":"16899739868365032574"}},"outputId":"04390310-2d85-4fd0-9cf1-9bab29a4412e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ultralytics\n","  Downloading ultralytics-8.3.31-py3-none-any.whl.metadata (35 kB)\n","Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n","Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.8.0)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (11.0.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.0+cu121)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.0+cu121)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.6)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n","Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n","  Downloading ultralytics_thop-2.0.11-py3-none-any.whl.metadata (9.4 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.54.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n","Downloading ultralytics-8.3.31-py3-none-any.whl (886 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m886.3/886.3 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ultralytics_thop-2.0.11-py3-none-any.whl (26 kB)\n","Installing collected packages: ultralytics-thop, ultralytics\n","Successfully installed ultralytics-8.3.31 ultralytics-thop-2.0.11\n"]}],"source":["!pip install ultralytics"]},{"cell_type":"code","source":["import os\n","import shutil\n","import numpy as np\n","import random\n","!pip install tqdm --upgrade\n","from tqdm.notebook import tqdm\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vbbeXzwZAyoE","executionInfo":{"status":"ok","timestamp":1731599509401,"user_tz":-330,"elapsed":3764,"user":{"displayName":"Sai Kiran","userId":"16899739868365032574"}},"outputId":"34454005-4321-4e8a-bae9-0af5591b16a8"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n","Collecting tqdm\n","  Downloading tqdm-4.67.0-py3-none-any.whl.metadata (57 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tqdm-4.67.0-py3-none-any.whl (78 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tqdm\n","  Attempting uninstall: tqdm\n","    Found existing installation: tqdm 4.66.6\n","    Uninstalling tqdm-4.66.6:\n","      Successfully uninstalled tqdm-4.66.6\n","Successfully installed tqdm-4.67.0\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tLJDPBFQBoCr","executionInfo":{"status":"ok","timestamp":1731599632853,"user_tz":-330,"elapsed":31028,"user":{"displayName":"Sai Kiran","userId":"16899739868365032574"}},"outputId":"be03c5f2-4244-4d91-ffbe-518bb79fb4ca"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import ultralytics\n","ultralytics.checks()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AYuyoFMFGXCA","executionInfo":{"status":"ok","timestamp":1731599647600,"user_tz":-330,"elapsed":8200,"user":{"displayName":"Sai Kiran","userId":"16899739868365032574"}},"outputId":"04cb9f4b-857c-4a1c-c7ae-ebaf3f33eb89"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.31 🚀 Python-3.10.12 torch-2.5.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","Setup complete ✅ (2 CPUs, 12.7 GB RAM, 32.4/112.6 GB disk)\n"]}]},{"cell_type":"markdown","source":["!yolo task=detect mode=train model=yolov8n.pt data=/content/drive/MyDrive/parking.ai/mydata128.yaml epochs=10 imgsz=640 batch=8 project=/content/drive/MyDrive/parking.ai/training_results name=car"],"metadata":{"id":"7Zpin900GvP-"}},{"cell_type":"code","source":["train_path_img= \"./yolo_data/images/train\"\n","train_path_label= \"./yolo_data/labels/train\"\n","val_path_img= \"./yolo_data/images/val\"\n","val_path_label= \"./yolo_data/labels/val\"\n","test_path= \"./yolo_data/test\""],"metadata":{"id":"GuFDHts00hPF","executionInfo":{"status":"ok","timestamp":1731599647601,"user_tz":-330,"elapsed":8,"user":{"displayName":"Sai Kiran","userId":"16899739868365032574"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def train_test_split(path,neg_path=None, split=0.2):\n","    print(\"Started Splitting\")\n","    # Use os.path.splitext to split the filename from the extension\n","    files = list (set([os.path.splitext(name)[0] for name in os.listdir(path)]))\n","    print(f\"--- this folder has a total number of (len(files)) images---\")\n","    random.seed(42)\n","    random.shuffle(files)\n","    test_size = int(len(files) * split)\n","    train_size = len(files) - test_size\n","    os.makedirs(train_path_img, exist_ok=True)\n","    os.makedirs(train_path_label, exist_ok=True)\n","    os.makedirs(val_path_img, exist_ok=True)\n","    os.makedirs(val_path_label, exist_ok=True)\n","    for filex in tqdm(files[:train_size]):\n","        if filex == \"class\":\n","          continue\n","        # Use os.path.join to safely concatenate paths\n","        shutil.copy2(os.path.join(path, filex + '.jpg'), os.path.join(train_path_img, filex + '.jpg'))\n","        shutil.copy2(os.path.join(path, filex + '.json'), os.path.join(train_path_label, filex + '.json'))\n","    print(f\"-----training data created with 80% split {len(files[:train_size])} images----- \")\n","    if neg_path is not None:\n","      # Use os.path.splitext to split the filename from the extension\n","      neg_images = list(set([os.path.splitext(name)[0] for name in os.listdir(neg_path)]))\n","      for filex in tqdm(neg_images):\n","        # Use os.path.join to safely concatenate paths\n","        shutil.copy2(os.path.join(neg_path, filex + \".jpg\"), os.path.join(train_path_img, filex + \".jpg\"))\n","      print (f\"total {len(neg_images)} negative images added to the training data\")\n","      print(f\"-----training data created with 80% split {len(files[:train_size]) + len(neg_images)} images----- \")\n","\n","\n","\n","    ###copying images in a validation folder\n","    for filex in tqdm(files[train_size:]):\n","      if filex == \"class\":\n","        continue\n","      shutil.copy2(os.path.join(path, filex +\".jpg\"), os.path.join(val_path_img, filex + \".jpg\"))\n","      shutil.copy2(os.path.join(path, filex +\".json\"), os.path.join(val_path_label, filex + \".json\"))\n","    print(f\"-----validation data created with 20% split {len(files[train_size:])} images----- \")\n","    print (\"Splitting Done\")\n","\n","\n","train_test_split('/content/drive/MyDrive/parking.ai/archive (1)/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":168,"referenced_widgets":["31cea186f069457b8fbcaf3c45edfbf5","81faa191ce0b4bfd84e744bf90719502","bce7460107a94f8eb1d1d1464c9b41b7","fcc6ac6d76bc428d99cf414cbcaa2e08","b379b57db7c24e7daa06646ae5efb489","6ed1e4070acb4ab88573f323c5a7a096","440cd9b027a543e2a1b6cbe3e936627d","4c4b76cccc024da7b95c7f08cb1b74de","029d30d098d14796bea219657c71f3f9","c7ecf798d5654834a97b4d204f5323ee","7085a0db00c04ab89eeb3d7c9a1c6ed1","971309971cf1445c9e350380048399d9","2094b3c34cb240cb8282e306b78c3939","55841be796e546d29b24af0c2ec1bd3c","aff06009375c42f79ca3b7c2477c3664","1ecd3f0667384085b04138ec2ff6b1c5","dc28e4fe04bd44239740d8e240767809","5d12733097de42888d353c53a1c2ca69","85ba7706829b4c969c961ed413ec9637","3bf749e425844789a103c3e7dc07fa77","09fe82f775cb4843af03a49da2e8379c","86327ed9f7894ceabc0e426755954ca0"]},"id":"nz5qnZCIGHec","executionInfo":{"status":"ok","timestamp":1731599657851,"user_tz":-330,"elapsed":10257,"user":{"displayName":"Sai Kiran","userId":"16899739868365032574"}},"outputId":"e9f9e5f9-8e1b-4297-e320-a36575b2b99c"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Started Splitting\n","--- this folder has a total number of (len(files)) images---\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/120 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31cea186f069457b8fbcaf3c45edfbf5"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["-----training data created with 80% split 120 images----- \n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/30 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"971309971cf1445c9e350380048399d9"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["-----validation data created with 20% split 30 images----- \n","Splitting Done\n"]}]},{"cell_type":"code","source":["!yolo task=detect mode=train model=yolov8s.pt data=/content/drive/MyDrive/parking.ai/yolo.yaml epochs=10 imgsz=640 batch=8 project=/content/drive/MyDrive/parking.ai/training_results name=Car"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3yyZx4sxaPk3","executionInfo":{"status":"ok","timestamp":1731600898420,"user_tz":-330,"elapsed":69736,"user":{"displayName":"Sai Kiran","userId":"16899739868365032574"}},"outputId":"ff555e40-1ea1-48aa-9932-120e4f57151a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.31 🚀 Python-3.10.12 torch-2.5.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/content/drive/MyDrive/parking.ai/yolo.yaml, epochs=10, time=None, patience=100, batch=8, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=/content/drive/MyDrive/parking.ai/training_results, name=Car, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/drive/MyDrive/parking.ai/training_results/Car\n","Overriding model.yaml nc=80 with nc=1\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2116435  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \n","Model summary: 225 layers, 11,135,987 parameters, 11,135,971 gradients, 28.6 GFLOPs\n","\n","Transferred 349/355 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/drive/MyDrive/parking.ai/training_results/Car', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolo_data/labels/train.cache... 0 images, 120 backgrounds, 0 corrupt: 100% 120/120 [00:00<?, ?it/s]\n","WARNING ⚠️ No labels found in /content/yolo_data/labels/train.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n","/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n","  check_for_updates()\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolo_data/labels/val.cache... 0 images, 30 backgrounds, 0 corrupt: 100% 30/30 [00:00<?, ?it/s]\n","WARNING ⚠️ No labels found in /content/yolo_data/labels/val.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n","Plotting labels to /content/drive/MyDrive/parking.ai/training_results/Car/labels.jpg... \n","zero-size array to reduction operation maximum which has no identity\n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/content/drive/MyDrive/parking.ai/training_results/Car\u001b[0m\n","Starting training for 10 epochs...\n","Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       1/10      2.08G          0        367          0          0        640: 100% 15/15 [00:03<00:00,  4.29it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  2.91it/s]\n","                   all         30          0          0          0          0          0\n","WARNING ⚠️ no labels found in detect set, can not compute metrics without labels\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       2/10      2.07G          0      274.8          0          0        640: 100% 15/15 [00:03<00:00,  4.26it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  2.31it/s]\n","                   all         30          0          0          0          0          0\n","WARNING ⚠️ no labels found in detect set, can not compute metrics without labels\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       3/10      2.06G          0      70.55          0          0        640: 100% 15/15 [00:02<00:00,  5.29it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  7.11it/s]\n","                   all         30          0          0          0          0          0\n","WARNING ⚠️ no labels found in detect set, can not compute metrics without labels\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       4/10      2.05G          0      28.07          0          0        640: 100% 15/15 [00:02<00:00,  6.40it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  8.63it/s]\n","                   all         30          0          0          0          0          0\n","WARNING ⚠️ no labels found in detect set, can not compute metrics without labels\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       5/10      2.08G          0       11.8          0          0        640: 100% 15/15 [00:02<00:00,  6.76it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  7.71it/s]\n","                   all         30          0          0          0          0          0\n","WARNING ⚠️ no labels found in detect set, can not compute metrics without labels\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       6/10      2.13G          0      6.953          0          0        640: 100% 15/15 [00:03<00:00,  4.95it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  6.46it/s]\n","                   all         30          0          0          0          0          0\n","WARNING ⚠️ no labels found in detect set, can not compute metrics without labels\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       7/10      2.13G          0      4.484          0          0        640: 100% 15/15 [00:03<00:00,  4.50it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  8.16it/s]\n","                   all         30          0          0          0          0          0\n","WARNING ⚠️ no labels found in detect set, can not compute metrics without labels\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       8/10      2.13G          0       3.91          0          0        640: 100% 15/15 [00:02<00:00,  6.87it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  9.49it/s]\n","                   all         30          0          0          0          0          0\n","WARNING ⚠️ no labels found in detect set, can not compute metrics without labels\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       9/10      2.13G          0      2.867          0          0        640: 100% 15/15 [00:02<00:00,  7.07it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  8.83it/s]\n","                   all         30          0          0          0          0          0\n","WARNING ⚠️ no labels found in detect set, can not compute metrics without labels\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      10/10      2.13G          0      2.422          0          0        640: 100% 15/15 [00:02<00:00,  5.67it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  4.60it/s]\n","                   all         30          0          0          0          0          0\n","WARNING ⚠️ no labels found in detect set, can not compute metrics without labels\n","\n","10 epochs completed in 0.013 hours.\n","Optimizer stripped from /content/drive/MyDrive/parking.ai/training_results/Car/weights/last.pt, 22.5MB\n","Optimizer stripped from /content/drive/MyDrive/parking.ai/training_results/Car/weights/best.pt, 22.5MB\n","\n","Validating /content/drive/MyDrive/parking.ai/training_results/Car/weights/best.pt...\n","Ultralytics 8.3.31 🚀 Python-3.10.12 torch-2.5.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","Model summary (fused): 168 layers, 11,125,971 parameters, 0 gradients, 28.4 GFLOPs\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 2/2 [00:00<00:00,  4.31it/s]\n","                   all         30          0          0          0          0          0\n","WARNING ⚠️ no labels found in detect set, can not compute metrics without labels\n","Speed: 0.2ms preprocess, 6.4ms inference, 0.0ms loss, 2.9ms postprocess per image\n","Results saved to \u001b[1m/content/drive/MyDrive/parking.ai/training_results/Car\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/train\n"]}]}]}